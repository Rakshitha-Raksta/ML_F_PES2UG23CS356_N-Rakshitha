{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-6S_xILu4aZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    f1_score\n",
        ")\n",
        "\n",
        "# ============================================\n",
        "# Data loading function (DO NOT CHANGE)\n",
        "# ============================================\n",
        "def load_pubmed_rct_file(filepath):\n",
        "    labels, sentences = [], []\n",
        "    with open(filepath, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line or '\\t' not in line:\n",
        "                continue\n",
        "            label, sent = line.split('\\t', maxsplit=1)\n",
        "            labels.append(label)\n",
        "            sentences.append(sent)\n",
        "    return pd.DataFrame({'label': labels, 'sentence': sentences})\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# Naive Bayes From Scratch\n",
        "# ============================================\n",
        "class NaiveBayesClassifier:\n",
        "    def __init__(self, alpha=1.0):\n",
        "        self.alpha = alpha\n",
        "        self.class_priors = {}\n",
        "        self.feature_log_probs = {}\n",
        "        self.classes = None\n",
        "        self.vocabulary_size = 0\n",
        "\n",
        "    def fit(self, X_counts, y):\n",
        "        y_array = y.to_numpy()\n",
        "        self.classes = np.unique(y_array)\n",
        "        self.vocabulary_size = X_counts.shape[1]\n",
        "\n",
        "        for c in self.classes:\n",
        "            X_c = X_counts[y_array == c]\n",
        "\n",
        "            # Log prior\n",
        "            self.class_priors[c] = np.log(X_c.shape[0] / X_counts.shape[0])\n",
        "\n",
        "            # Count sum of words in class\n",
        "            feature_sum = X_c.sum(axis=0).A1\n",
        "            total_mass = np.sum(feature_sum)\n",
        "\n",
        "            # Laplace smoothing\n",
        "            numerator = feature_sum + self.alpha\n",
        "            denominator = total_mass + (self.alpha * self.vocabulary_size)\n",
        "\n",
        "            # Log likelihoods\n",
        "            self.feature_log_probs[c] = np.log(numerator / denominator)\n",
        "\n",
        "    def predict(self, X_counts):\n",
        "        y_pred = []\n",
        "        for i in range(X_counts.shape[0]):\n",
        "            x_i = X_counts.getrow(i)\n",
        "            scores = {}\n",
        "\n",
        "            for c in self.classes:\n",
        "                log_prob = self.class_priors[c]\n",
        "                log_likelihoods = self.feature_log_probs[c]\n",
        "\n",
        "                non_zero_index = x_i.indices\n",
        "                non_zero_val = x_i.data\n",
        "\n",
        "                # Add ∑ count(w) * log(P(w|C))\n",
        "                log_prob += np.sum(non_zero_val * log_likelihoods[non_zero_index])\n",
        "                scores[c] = log_prob\n",
        "\n",
        "            predicted_class = max(scores, key=scores.get)\n",
        "            y_pred.append(predicted_class)\n",
        "\n",
        "        return np.array(y_pred)\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# Load Dataset (TODO completed)\n",
        "# ============================================\n",
        "train_df = load_pubmed_rct_file(\"/content/train.txt\")\n",
        "dev_df   = load_pubmed_rct_file(\"/content/dev.txt\")\n",
        "test_df  = load_pubmed_rct_file(\"/content/test.txt\")\n",
        "\n",
        "# ============================================\n",
        "# Vectorization\n",
        "# ============================================\n",
        "vectorizer = CountVectorizer(lowercase=True, stop_words=None)\n",
        "X_train = vectorizer.fit_transform(train_df[\"sentence\"])\n",
        "X_dev   = vectorizer.transform(dev_df[\"sentence\"])\n",
        "X_test  = vectorizer.transform(test_df[\"sentence\"])\n",
        "\n",
        "# ============================================\n",
        "# Train custom NB model\n",
        "# ============================================\n",
        "nb_model = NaiveBayesClassifier(alpha=1.0)\n",
        "nb_model.fit(X_train, train_df[\"label\"])\n",
        "\n",
        "# ============================================\n",
        "# Predictions\n",
        "# ============================================\n",
        "y_pred = nb_model.predict(X_test)\n",
        "\n",
        "# ============================================\n",
        "# Metrics\n",
        "# ============================================\n",
        "print(\"Accuracy:\", accuracy_score(test_df[\"label\"], y_pred))\n",
        "print(\"F1 Score:\", f1_score(test_df[\"label\"], y_pred, average=\"macro\"))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(test_df[\"label\"], y_pred))\n",
        "\n",
        "cm = confusion_matrix(test_df[\"label\"], y_pred)\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap=\"Blues\")\n",
        "plt.title(\"Confusion Matrix - Custom Naive Bayes\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and Prepare Data (DO NOT CHANGE FILE PATHS)\n",
        "dir_path = '/content/'\n",
        "\n",
        "try:\n",
        "    train_df = load_pubmed_rct_file(os.path.join(dir_path, 'train.txt'))\n",
        "    dev_df   = load_pubmed_rct_file(os.path.join(dir_path, 'dev.txt'))\n",
        "    test_df  = load_pubmed_rct_file(os.path.join(dir_path, 'test.txt'))\n",
        "\n",
        "    print(f\"Train samples: {len(train_df)}\")\n",
        "    print(f\"Dev   samples: {len(dev_df)}\")\n",
        "    print(f\"Test  samples: {len(test_df)}\")\n",
        "\n",
        "    X_train, y_train = train_df['sentence'], train_df['label']\n",
        "    X_dev,   y_dev   = dev_df['sentence'],   dev_df['label']\n",
        "    X_test,  y_test  = test_df['sentence'],  test_df['label']\n",
        "\n",
        "    target_names = sorted(y_train.unique())\n",
        "    print(f\"Classes: {target_names}\")\n",
        "\n",
        "except FileNotFoundError as e:\n",
        "    print(\"❌ Dataset file not found. Upload train.txt, dev.txt, test.txt to /content/\")\n"
      ],
      "metadata": {
        "id": "SsgN2aX_vLGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Extraction and Custom Model Training\n",
        "if X_train is not None and len(X_train) > 0:\n",
        "\n",
        "    # Initialize and fit the CountVectorizer for count-based features\n",
        "    count_vectorizer = CountVectorizer(\n",
        "        lowercase=True,\n",
        "        strip_accents='unicode',\n",
        "        stop_words='english',\n",
        "        # Using unigrams + bigrams for better context\n",
        "        ngram_range=(1, 2),\n",
        "        # Ignore extremely rare words\n",
        "        min_df=2\n",
        "    )\n",
        "\n",
        "    print(\"Fitting Count Vectorizer and transforming training data...\")\n",
        "    # Fit vectorizer on training data & transform\n",
        "    X_train_counts = count_vectorizer.fit_transform(X_train)\n",
        "    print(f\"Vocabulary size: {X_train_counts.shape[1]}\")\n",
        "\n",
        "    print(\"Transforming test data...\")\n",
        "    # Transform X_test using the same vectorizer\n",
        "    X_test_counts = count_vectorizer.transform(X_test)\n",
        "\n",
        "    # Train Custom Naive Bayes Classifier\n",
        "    print(\"\\nTraining the Custom Naive Bayes Classifier (from scratch)...\")\n",
        "\n",
        "    # Initialize the custom NaiveBayesClassifier\n",
        "    nb_model = NaiveBayesClassifier(alpha=1.0)\n",
        "\n",
        "    # Fit on training data\n",
        "    nb_model.fit(X_train_counts, y_train)\n",
        "    print(\"Training complete.\")\n",
        "\n",
        "else:\n",
        "    print(\"Skipping feature extraction and training: Training data is empty or not loaded.\")\n"
      ],
      "metadata": {
        "id": "5EYBRuisvQV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict and evaluate on test set\n",
        "print(\"\\n=== Test Set Evaluation (Custom Count-Based Naive Bayes) ===\")\n",
        "\n",
        "# Predict y_test_pred using X_test_counts\n",
        "y_test_pred = nb_model.predict(X_test_counts)\n",
        "\n",
        "if y_test_pred is not None:\n",
        "    print(f\"Accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")\n",
        "    print(classification_report(y_test, y_test_pred, target_names=target_names))\n",
        "    test_f1 = f1_score(y_test, y_test_pred, average='macro')\n",
        "    print(f\"Macro-averaged F1 score: {test_f1:.4f}\")\n",
        "else:\n",
        "    print(\"Prediction step failed or incomplete.\")\n"
      ],
      "metadata": {
        "id": "GM6pbw6rvYvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix on test set\n",
        "    # // TODO: Use the confusion_matrix, matplotlib, and seaborn libraries to generate\n",
        "    # a visual confusion matrix (heatmap) for the predicted results.\n",
        "    # if y_test_pred is not None:\n",
        "    #     cm = confusion_matrix(...)\n",
        "    #     plt.figure(...)\n",
        "    #     sns.heatmap(...)\n",
        "    #     plt.show()\n",
        "    # Confusion Matrix on test set\n",
        "if y_test_pred is not None:\n",
        "    cm = confusion_matrix(y_test, y_test_pred, labels=target_names)\n",
        "\n",
        "    plt.figure(figsize=(7,5))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=target_names,\n",
        "                yticklabels=target_names)\n",
        "\n",
        "    plt.title(\"Confusion Matrix - Custom Naive Bayes (Count Features)\")\n",
        "    plt.xlabel(\"Predicted Label\")\n",
        "    plt.ylabel(\"True Label\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Confusion Matrix cannot be generated — predictions missing.\")\n"
      ],
      "metadata": {
        "id": "zrKVdOi3vekj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
        "\n",
        "# Define a Pipeline using TfidfVectorizer and MultinomialNB\n",
        "pipeline = Pipeline([\n",
        "    (\"tfidf\", TfidfVectorizer(\n",
        "        lowercase=True,\n",
        "        stop_words='english',\n",
        "        strip_accents='unicode'\n",
        "    )),\n",
        "    (\"nb\", MultinomialNB())\n",
        "])\n",
        "\n",
        "# Train the initial pipeline on the training set\n",
        "print(\"Training initial Naive Bayes pipeline...\")\n",
        "pipeline.fit(X_train, y_train)\n",
        "print(\"Training complete.\")\n",
        "\n",
        "# Predict and evaluate on the test set\n",
        "print(\"\\n=== Test Set Evaluation (Initial Sklearn Model) ===\")\n",
        "y_test_pred = pipeline.predict(X_test)\n",
        "\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")\n",
        "print(classification_report(y_test, y_test_pred, target_names=target_names))\n",
        "print(f\"Macro-averaged F1 score: {f1_score(y_test, y_test_pred, average='macro'):.4f}\")\n",
        "\n",
        "# Hyperparameter Tuning using GridSearchCV\n",
        "param_grid = {\n",
        "    \"tfidf__ngram_range\": [(1,1), (1,2), (1,3)],\n",
        "    \"tfidf__min_df\": [1, 2, 5],\n",
        "    \"nb__alpha\": [0.1, 0.5, 1.0]\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(\n",
        "    pipeline,\n",
        "    param_grid,\n",
        "    cv=3,\n",
        "    scoring='f1_macro',\n",
        "    verbose=1,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "print(\"\\nStarting Hyperparameter Tuning on Development Set...\")\n",
        "grid.fit(X_dev, y_dev)\n",
        "print(\"Grid search complete.\")\n",
        "\n",
        "# Print best parameters and best score\n",
        "print(\"\\n=== Best Hyperparameters (Grid Search) ===\")\n",
        "print(grid.best_params_)\n",
        "print(f\"Best Dev F1 Score: {grid.best_score_:.4f}\")\n"
      ],
      "metadata": {
        "id": "xmrFIM0Pvlo1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# =======================================================\n",
        "# Dynamic Data Sampling (DO NOT CHANGE)\n",
        "# =======================================================\n",
        "BASE_SAMPLE_SIZE = 10000\n",
        "\n",
        "FULL_SRN = input(\"Please enter your full SRN (e.g., PES1UG22CS345): \")\n",
        "\n",
        "try:\n",
        "    if len(FULL_SRN) >= 3:\n",
        "        srn_suffix_str = FULL_SRN[-3:]\n",
        "        srn_value = int(srn_suffix_str)\n",
        "    else:\n",
        "        raise ValueError(\"SRN too short.\")\n",
        "except:\n",
        "    print(\"WARNING: SRN input failed or format is incorrect. Using 10000.\")\n",
        "    srn_value = 0\n",
        "\n",
        "SAMPLE_SIZE = BASE_SAMPLE_SIZE + srn_value\n",
        "print(f\"Using dynamic sample size: {SAMPLE_SIZE}\")\n",
        "\n",
        "# Placeholder data if missing\n",
        "if 'X_train' not in globals() or len(X_train) == 0:\n",
        "    print(\"Warning: Training data not found. Using small placeholder data.\")\n",
        "    X_train = pd.Series([\"sample text one\"] * 11000)\n",
        "    y_train = pd.Series([\"BACKGROUND\"] * 5000 + [\"METHODS\"] * 6000)\n",
        "    X_test = pd.Series([\"test text one\", \"test text two\"])\n",
        "    y_test = pd.Series([\"BACKGROUND\", \"METHODS\"])\n",
        "    target_names = [\"BACKGROUND\", \"CONCLUSIONS\", \"METHODS\", \"OBJECTIVE\", \"RESULTS\"]\n",
        "\n",
        "effective_sample_size = min(SAMPLE_SIZE, len(X_train))\n",
        "X_train_sampled = X_train[:effective_sample_size]\n",
        "y_train_sampled = y_train[:effective_sample_size]\n",
        "print(f\"Actual sampled training set size used: {effective_sample_size}\")\n",
        "\n",
        "# =======================================================\n",
        "# Define Base Learners (DO NOT CHANGE)\n",
        "# =======================================================\n",
        "tfidf_params = {\n",
        "    'lowercase': True,\n",
        "    'strip_accents': 'unicode',\n",
        "    'stop_words': 'english',\n",
        "    'ngram_range': (1, 1),\n",
        "    'min_df': 5\n",
        "}\n",
        "\n",
        "h1_nb = Pipeline([('tfidf', TfidfVectorizer(**tfidf_params)), ('clf', MultinomialNB(alpha=1.0, fit_prior=False))])\n",
        "h2_lr = Pipeline([('tfidf', TfidfVectorizer(**tfidf_params)), ('clf', LogisticRegression(solver='liblinear', max_iter=1000, random_state=42))])\n",
        "h3_rf = Pipeline([('tfidf', TfidfVectorizer(**tfidf_params)), ('clf', CalibratedClassifierCV(RandomForestClassifier(n_estimators=50, max_depth=10, random_state=42), cv=3, method='isotonic'))])\n",
        "h4_dt = Pipeline([('tfidf', TfidfVectorizer(**tfidf_params)), ('clf', CalibratedClassifierCV(DecisionTreeClassifier(max_depth=10, random_state=42), cv=3, method='isotonic'))])\n",
        "h5_knn = Pipeline([('tfidf', TfidfVectorizer(**tfidf_params)), ('clf', CalibratedClassifierCV(KNeighborsClassifier(n_neighbors=5), cv=3, method='isotonic'))])\n",
        "\n",
        "hypotheses = [h1_nb, h2_lr, h3_rf, h4_dt, h5_knn]\n",
        "hypothesis_names = ['NaiveBayes', 'LogisticRegression', 'RandomForest', 'DecisionTree', 'KNN']\n",
        "\n",
        "# =======================================================\n",
        "# ✅ Train Base Models\n",
        "# =======================================================\n",
        "print(\"\\nTraining all base models...\")\n",
        "for model in hypotheses:\n",
        "    model.fit(X_train_sampled, y_train_sampled)\n",
        "print(\"All base models trained.\")\n",
        "\n",
        "# =======================================================\n",
        "# ✅ Compute Posterior Weights\n",
        "# =======================================================\n",
        "X_sub, X_val, y_sub, y_val = train_test_split(\n",
        "    X_train_sampled, y_train_sampled, test_size=0.2, random_state=42, stratify=y_train_sampled\n",
        ")\n",
        "\n",
        "log_likelihoods = []\n",
        "eps = 1e-12\n",
        "\n",
        "for model in hypotheses:\n",
        "    model.fit(X_sub, y_sub)\n",
        "    probs = model.predict_proba(X_val)\n",
        "    classes = model.classes_\n",
        "    idx = {c: i for i, c in enumerate(classes)}\n",
        "\n",
        "    true_probs = np.array([probs[i][idx[y]] if y in idx else eps for i, y in enumerate(y_val)])\n",
        "    log_likelihood = np.sum(np.log(true_probs + eps))\n",
        "    log_likelihoods.append(log_likelihood)\n",
        "\n",
        "shifted = np.array(log_likelihoods) - np.max(log_likelihoods)\n",
        "exp_vals = np.exp(shifted)\n",
        "posterior_weights = exp_vals / np.sum(exp_vals)\n",
        "\n",
        "print(\"\\nPosterior Weights (P(h|D)):\", posterior_weights)\n",
        "\n",
        "# =======================================================\n",
        "# ✅ Voting Classifier (BOC Approximation)\n",
        "# =======================================================\n",
        "estimators = list(zip(hypothesis_names, hypotheses))\n",
        "\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "boc_soft_voter = VotingClassifier(\n",
        "    estimators=estimators,\n",
        "    voting='soft',\n",
        "    weights=posterior_weights\n",
        ")\n",
        "\n",
        "print(\"\\nFitting the VotingClassifier (BOC approximation)...\")\n",
        "boc_soft_voter.fit(X_train_sampled, y_train_sampled)\n",
        "print(\"Fitting complete.\")\n",
        "\n",
        "# =======================================================\n",
        "# ✅ Final Prediction on Test Set\n",
        "# =======================================================\n",
        "print(\"\\nPredicting on test set...\")\n",
        "y_pred = boc_soft_voter.predict(X_test)\n",
        "\n",
        "print(\"\\n=== Final Evaluation: Bayes Optimal Classifier (Soft Voting) ===\")\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
        "\n",
        "print(f\"Accuracy: {acc:.4f}\")\n",
        "print(f\"Macro F1 Score: {f1:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred, labels=np.unique(y_test))\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=np.unique(y_test),\n",
        "            yticklabels=np.unique(y_test))\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix - BOC Soft Voting\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "JTYYoOlHwIgR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}